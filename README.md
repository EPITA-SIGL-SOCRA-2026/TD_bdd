# TD ‚Äî Bases de Donn√©es & So-Close

Ce projet contient les supports de TD pour manipuler plusieurs types de bases de donn√©es avec un jeu de donn√©es commun sur les jardins comestibles parisiens.

---

## üß± Objectif

- Comprendre les diff√©rences fondamentales entre mod√®les de donn√©es

Pour chaque moteur, vous devrez :

- Charger les donn√©es via des scripts `SQL` ou API sp√©cifiques
- Explorer les donn√©es via des requ√™tes adapt√©es
- R√©pondre √† des questions cibl√©es li√©es au projet So-Close

---

## Exemple de SGBD Relationnelle: üêò PostgreSQL

**Objectif**: Cr√©er le sch√©ma de base de so-close en utilisant un mod√®le relationnel.

### Configuration de PostgreSQL

1. Lancez le conteneur PostgreSQL :

```bash
docker compose up -d postgres
```

2. V√©rfiez que vous pouvez vous connecter au shell PostgreSQL :

```bash
docker compose exec -it postgres psql -U so_close_user -d so_close_db

# Exemple d'output :
# psql (14.18 (Debian 14.18-1.pgdg120+1))
# Type "help" for help.

# so_close_db=#
```

> Note: pour quitter le shell PostgreSQL, tapez `\q`

### Chargement des donn√©es

√Ä ce stade, la base de donn√©es est vide.

Voici les √©tapes pour charger les donn√©es :

1. **G√©n√©rez les donn√©es** en suivant [les instructions dans le dossier script](scripts/README.md).
   - uniquement pour PostreSQL pour l'instant
2. **Cr√©ez les tables** en ex√©cutant le script `scripts/create_tables.sql` :

```bash
docker compose exec -it postgres psql -U so_close_user -d so_close_db -f scripts/create_tables.sql
```

3. **Ins√©rez les donn√©es** en ex√©cutant le script `scripts/load_data.sql` :

```bash
docker compose exec -it postgres psql -U so_close_user -d so_close_db -f scripts/load_data.sql
```

4. **V√©rifiez les donn√©es** avec une requ√™te simple :

```bash
docker compose exec -it postgres psql -U so_close_user -d so_close_db -c "SELECT * FROM jardins LIMIT 10;"
```

### üîé √ânigmes √† r√©soudre

- `Q1:` Combien y-a-t-il de **plantes diff√©rentes** dans la base ?
- `Q2:` Combien de **jardins** ont √©t√© g√©n√©r√©s ?
- `Q3:` Combien de **strates** diff√©rentes sont pr√©sentes dans la table des plantes ?
- `Q4:` Quelle plante est cultiv√©e dans le **plus grand nombre de jardins** ?
- `Q5:` Quels sont les **jardins ayant le plus de jardiniers** dans un rayon de 1 km autour du point (lat: `48.8566`, long: `2.3522`) ?

> Note: pour la derni√®re question, vous avez le choix:
>
> - **Option 1**: utiliser une function personnalis√©e SQL (par exemple `haversine`)

```sql
CREATE OR REPLACE FUNCTION haversine_distance(
    lat1 double precision, lon1 double precision,
    lat2 double precision, lon2 double precision
) RETURNS double precision AS $$
DECLARE
    r double precision := 6371; -- Rayon de la Terre en km
    dlat double precision := radians(lat2 - lat1);
    dlon double precision := radians(lon2 - lon1);
    a double precision;
    c double precision;
BEGIN
    a := sin(dlat / 2)^2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)^2;
    c := 2 * atan2(sqrt(a), sqrt(1 - a));
    RETURN r * c;
END;
$$ LANGUAGE plpgsql IMMUTABLE;
```

> et appeler la fonction dans une requ√™te :
>
> ```sql
> SELECT * FROM jardins WHERE haversine_distance(latitude, longitude, 48.8566, 2.3522) <= 1;
> ```

> - **Option 2**: utiliser une extension PostgreSQL comme `postgis` pour les calculs g√©ographiques

```sh
# Cr√©ez l'extension PostGIS
docker compose exec -it postgres psql -U so_close_user -d so_close_db -c "CREATE EXTENSION postgis;"
```

> Puis executez la requ√™te suivante :

```sql
SELECT *
FROM jardins
WHERE ST_Distance(
  geography(ST_MakePoint(longitude, latitude)),
  geography(ST_MakePoint(2.3522, 48.8566))
) <= 2000; -- en m√®tres (2 km)
```

### Si rien ne va, et vous voulez tout recommencer

- A√Øe, rien ne va plus ? Pas de panique, vous pouvez tout r√©initialiser :

```bash
docker compose down -v
docker compose up -d postgres
```

---

## Exemple de SGBD Doumentaire: üçÉ MongoDB

**Objectif**: Utiliser MongoDB pour stocker des commentaires sur les diff√©rentes cultures.

### Configuration de MongoDB

1. Lancez le conteneur MongoDB :

```bash
docker compose up -d mongo
```

2. V√©rifiez que vous pouvez vous connecter au shell MongoDB :

```bash
docker compose exec -it mongo mongosh --username so_close_user --password so_close_password
```

### Chargement des donn√©es

√Ä ce stade, la base de donn√©es est vide.
Voici les √©tapes pour charger les donn√©es :

1. **G√©n√©rez les donn√©es pour MongoDB** en suivant [les instructions dans le dossier script](scripts/README.md#g√©n√©ration-de-donn√©es-pour-mongodb-generate_cultures_commentspy).
2. **Ins√©rez les donn√©es** en utilisant `mongoimport`

```bash
docker compose exec -it mongo mongoimport --username=so_close_user --password=so_close_password --db=so_close
_db --authenticationDatabase=admin --collection=commentaires --file=/data/commentaires.json --jsonArray

# Vous devriez voir un message indiquant le nombre de documents ins√©r√©s
# Par exemple:
# 2025-07-08T09:38:10.018+0000    connected to: mongodb://localhost/
# 2025-07-08T09:38:13.018+0000    [###########.............] so_close_db.commentaires     66.0MB/137MB (48.3%)
# 2025-07-08T09:38:16.018+0000    [#######################.] so_close_db.commentaires     131MB/137MB (95.9%)
# 2025-07-08T09:38:16.306+0000    [########################] so_close_db.commentaires     137MB/137MB (100.0%)
# 2025-07-08T09:38:16.307+0000    284613 document(s) imported successfully. 0 document(s) failed to import.
```

3. **V√©rifiez les donn√©es** avec une requ√™te simple :

```bash
docker compose exec -it mongo mongosh --username so_close_user --password so_close_password

# Dans le mongo shell
use so_close_db
db.commentaires.find().limit(10).pretty()
```

> Plus d'informations sur `mongosh` dans la [documentation officielle](https://www.mongodb.com/docs/mongodb-shell/crud/read/)

#### üîé √ânigmes √† r√©soudre

1. Trouvez tous les commentaires pour la plante avec l'ID `8`
1. Top 5 des plantes les plus comment√©es (regardez la fonction `aggregate` de MongoDB)
1. Le jardin le plus comment√© (regardez la finction `aggregate` de MongoDB et `$unwind`)

Que notez vous comme diff√©rences entre MongoDB et PostgreSQL ?

---

## Exemple de SGBD Colonne: üß± Cassandra

**Objectif**: Utiliser une base orient√©e colonnes (Cassandra) pour stocker les r√©coltes agricoles dans le temps, et optimiser les requ√™tes d‚Äôanalyse.

### Configuration de Cassandra

1. Lancez le conteneur Cassandra (depuis le dossier racine du projet) :

```bash
docker compose up -d cassandra
```

> Note: Cassandra peut prendre un peu de temps pour d√©marrer, soyez patient.

2. Assurez vous que vous pouvez vous connecter au shell Cassandra

```bash
# r√©-essayez plusieurs fois si n√©cessaire, cassandra peut prendre 1 √† 2 minutes √† d√©marrer
docker compose exec -it cassandra cqlsh
```

### Chargement des donn√©es

√Ä ce stade, la base de donn√©es est vide.
Voici les √©tapes pour charger les donn√©es :

1. **G√©n√©rez les donn√©es pour Cassandra** en suivant [les instructions dans le dossier script](scripts/README.md#g√©n√©ration-de-donn√©es-pour-cassandra-generate_cultures_recoltespy).
2. **Cr√©ez le "sch√©ma" (en r√©alit√© un ["keyspace"]())** en ex√©cutant le script
   `cql/create_keyspace.cql` :

```bash
docker compose exec -it cassandra cqlsh -f /cql/create_keyspace.cql
```

3. **Cr√©ez les tables** en ex√©cutant le script `cql/create_tables.cql` :

```bash
docker compose exec -it cassandra cqlsh -f /cql/create_tables.cql
```

4. **Ins√©rez les donn√©es** en ex√©cutant le script `cql/load_data.cql` :

```bash
docker compose exec -it cassandra cqlsh -f /cql/load_data.cql
```

### üîé √ânigmes √† r√©soudre

1. Lister les r√©coltes du jardin 12 sur les 3 derni√®res ann√©es
2. Comparer les quantit√©s de menthe entre 2023 et 2024
3. Comptez la quantit√© de r√©colte tout confondue pour le jardin 12 sur l'ann√©e 2024

### Diff√©rences avec un mod√®le relationnel et Cassandra

> Vous vous posez peut-√™tre la question : Pourquoi plusieurs tables‚ÄØ`cultures_par_jardin` et `cultures_par_plante` ?
>
> üîé Chaque table est con√ßue pour r√©pondre √† une seule requ√™te typique (ex. : "recoltes par jardin", "recoltes par plante").
>
> ‚úÖ Les donn√©es sont dupliqu√©es volontairement dans plusieurs tables.
>
> ‚öôÔ∏è C‚Äôest l‚Äôapplication (backend, script Python‚Ä¶) qui assure la coh√©rence entre les tables lors des insertions.

Les points suivants comparent la logique de mod√©lisation relationnelle classique avec la mod√©lisation sp√©cifique √† Cassandra, afin d‚Äôaider √† penser diff√©remment.

> Note: ces conclusions sont directement r√©sum√©es de [la documentation officielle de Cassandra](https://cassandra.apache.org/doc/latest/cassandra/developing/data-modeling/data-modeling_rdbms.html)

#### üîÑ Pens√©e relationnelle (SQL)

**Dans une base relationnelle classique :**

- On normalise les donn√©es (plusieurs tables li√©es par des cl√©s √©trang√®res)
- On utilise des jointures pour reconstruire les vues n√©cessaires
- Le sch√©ma est centr√© sur les donn√©es, pas les requ√™tes

Exemple :

- Une table utilisateurs
- Une table commandes
- Une table produits

‚Üí Requ√™te de reporting = plusieurs JOIN

#### üîÅ Pens√©e Cassandra (NoSQL orient√©e colonnes)

**Dans Cassandra :**

- Pas de jointures
- Les requ√™tes guident la structure des tables
- On duplique les donn√©es dans plusieurs tables adapt√©es √† des requ√™tes pr√©cises
- On privil√©gie des √©critures rapides, pour des lectures cibl√©es

#### üß† Changement de paradigme

| Relationnel                      | Cassandra                              |
| -------------------------------- | -------------------------------------- |
| Sch√©ma bas√© sur les entit√©s      | Sch√©ma bas√© sur les cas d‚Äôusage        |
| Normalisation                    | D√©normalisation                        |
| Acc√®s via requ√™tes dynamiques    | Acc√®s pr√©visibles et index√©s           |
| Relations inter-tables           | Regroupement de donn√©es dans une table |
| Transactions complexes possibles | Requ√™tes simples et rapides            |

#### üìå Conclusion (de la doc Cassandra)

- Pensez √† l‚Äôenvers : quelles sont les requ√™tes ?
- Cr√©ez une table par requ√™te
- Acceptez la duplication pour gagner en performance
- Structurez vos donn√©es autour de la cl√© de partition et de l‚Äôordre des clustering keys
- Anticipez vos acc√®s, car il n‚Äôy a pas de requ√™te universelle possible

---

## Exemple de SGBD Graph: üåø Neo4j

**Objectif**: Explorer les connexions. Trouver les utilisateurs proches selon leurs pratiques et leurs plantes.

### Configuration de Neo4j

1. Lancez le conteneur Neo4j :

```bash
docker compose up -d neo4j
```

2. V√©rifiez que vous pouvez vous connecter √† l'interface web de Neo4j :
   http://localhost:7474

3. Connectez-vous avec les identifiants par d√©faut (dans le [`docker-compose.yml`](docker-compose.yml)) :
   - **Utilisateur** : `neo4j`
   - **Mot de passe** : `so_close_password`

### Chargement des donn√©es

√Ä ce stade, la base de donn√©es est vide.

Nous n'allons pas utiliser de fichier CSV pour charger les donn√©es dans Neo4j, mais plut√¥t un script Python.

Voici les √©tapes pour charger les donn√©es :

1. **G√©n√©rez et inserez les donn√©es pour Neo4j** en suivant [les instructions dans le dossier script](scripts/README.md#g√©n√©ration-et-insertion-de-donn√©es-pour-neo4j-seed_neo4j_so_closepy).

2. **V√©rifiez les donn√©es** sur l'interface web de Neo4j en ex√©cutant la requ√™te suivante dans le navigateur :

```cypher
MATCH (u:Utilisateur)
RETURN u.nom AS Nom, size((u)-[:CULTIVE]->(:Plante)) AS Nombre_de_plantes
ORDER BY Nombre_de_plantes DESC
LIMIT 10;
```

### üîé √ânigmes √† r√©soudre

1. Jardiniers qui ont au moins 2 plantes en commun

```cypher
MATCH (a:Utilisateur)-[:CULTIVE]->(p:Plante)<-[:CULTIVE]-(b:Utilisateur)
WHERE a.nom < b.nom
WITH a, b, count(p) AS nb_communes
WHERE nb_communes >= 2
RETURN a.nom, b.nom, nb_communes
ORDER BY nb_communes DESC
```

2. Calculer la ‚Äúdistance‚Äù entre deux jardiniers (nombre de sauts), par exemple entre `Jardinier 1` et `Jardinier 42`

```cypher
MATCH (a:Utilisateur {nom: "Jardinier 1"}), (b:Utilisateur {nom: "Jardinier 42"}),
path = shortestPath((a)-[:CULTIVE*]-(b))
RETURN length(path) AS distance
```

3. Sugg√©rer des bin√¥mes compatibles

```cypher
MATCH (u1:Utilisateur)-[:CULTIVE]->(p:Plante)<-[:CULTIVE]-(u2:Utilisateur)
WHERE u1.nom < u2.nom
WITH u1, u2, count(p) AS affinite
WHERE affinite >= 3
RETURN u1.nom, u2.nom, affinite
ORDER BY affinite DESC
```

### √Ä retenir

**Pourquoi Neo4j ici plut√¥t que PostgreSQL ?**

| üîç Requ√™te                       | PostgreSQL                          | Neo4j                             |
| -------------------------------- | ----------------------------------- | --------------------------------- |
| Relations crois√©es entre n≈ìuds   | Requ√™tes tr√®s complexes avec JOIN   | Requ√™te naturelle et performante  |
| Recherches de voisins/connexions | Auto-jointures r√©cursives complexes | `shortestPath` direct             |
| Sugg√©rer des bin√¥mes             | CTE (table r√©cursive), agr√©gats     | Requ√™tes en 1 ligne               |
| Ajout de contexte au lien        | `table relationnelle` + attributs   | Ajout direct sur `[:CULTIVE {‚Ä¶}]` |

**Neo4j est bien plus adapt√© pour :**

- les relations multi-niveaux (graphe de co-cultures),
- les navigations de proximit√© (voisins, suggestions),
- les connexions implicites entre utilisateurs.

---

## Exemple de SGBD Cl√© Valeur: üß† Redis

**Objectif**: Utiliser Redis pour mettre en cache des fiches de plantes

**D√©marche**:

Mettre en cache les r√©ponses de l‚ÄôAPI `/api/plantes/:nom` dans Redis afin de :

- Am√©liorer la vitesse de r√©ponse utilisateur
- R√©duire les appels inutiles au backend ou √† la base de donn√©es

### Configuration de Redis

1. Lancez le conteneur Redis :

```bash
docker compose up -d redis
```

2. V√©rifiez que vous pouvez vous connecter au shell Redis :

```bash
docker compose exec -it redis redis-cli
```

### Lancer le web service

1. Dans le dossier `redis`:

```bash
# si vous avez nvm install√© sinon
# utilisez la version de node dans le fichier.nvmrc
nvm use
npm install
npm start
```

### Cache hit et cache miss

Sur deux terminaux diff√©rents, vous pouvez tester le cache :

```bash
# Terminal 1 : Lancer le serveur si ce n'est pas d√©j√† fait
# cd redis/
npm start

# Terminal 2 : Faire une requ√™te
curl http://localhost:3000/api/plantes/tomate
# puis la refaire une seconde fois
curl http://localhost:3000/api/plantes/tomate
```

Vous devriez voir dans le terminal du serveur :

![cache hit vs cache miss](docs/cache-hit-cache-miss.png)

### Vider le cache

Pour vider le cache, vous pouvez appeler l'endpoint `/admin/clear-cache` :

```bash
curl http://localhost:3000/admin/clear-cache
# R√©ponse : üóë Cache vid√©.
```

### Visualiser les cl√©s dans Redis CLI

```bash
docker exec -it soclose-redis redis-cli

# Dans le shell Redis CLI
## A remplacer en fonction des requetes que vous avez faites
> KEYS plante:*
> GET plante:tomate
> TTL plante:tomate
```

### üí° Concepts introduits

| Concept             | Description                                             |
| ------------------- | ------------------------------------------------------- |
| Cache-aside pattern | Lecture du cache avant fallback vers la DB              |
| TTL (Time To Live)  | Expiration automatique des donn√©es en cache (`EX 3600`) |
| Prefixing des cl√©s  | Organisation des entr√©es Redis (`plante:<nom>`)         |
| Gain de performance | Temps de r√©ponse r√©duit gr√¢ce au cache Redis            |

---

### Si vous souhaitez aller plus loin

- Ajouter un middleware pour chronom√©trer le temps de r√©ponse
- Simuler une latence avec `setTimeout` dans `getPlanteFromDb()`
